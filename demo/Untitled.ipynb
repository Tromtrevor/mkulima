{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1c31a11-fcca-4775-9fa2-f365851c5403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T01:33:23.287820Z",
     "iopub.status.busy": "2025-10-24T01:33:23.287382Z",
     "iopub.status.idle": "2025-10-24T01:33:23.306706Z",
     "shell.execute_reply": "2025-10-24T01:33:23.305881Z",
     "shell.execute_reply.started": "2025-10-24T01:33:23.287793Z"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from shapely.geometry import mapping\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- PATHS ---\n",
    "API_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJmcmVzaCI6ZmFsc2UsImlhdCI6MTc2MDEyMjI1MiwianRpIjoiMzEwNGJiMGQtYmVjMi00ZDYzLWJiM2MtMjQxMzZlNjBkNTIxIiwibmJmIjoxNzYwMTIyMjUyLCJ0eXBlIjoiYWNjZXNzIiwic3ViIjoiWTMxMXJuRGtYc1VhOUJicFFHdFBzZkJzeG1BMyIsImV4cCI6MTc2NTMwNjI1Miwicm9sZXMiOiJ1c2VyIiwidXNlcl9pZCI6IlkzMTFybkRrWHNVYTlCYnBRR3RQc2ZCc3htQTMifQ.yJChfnVBg0yMqhc-R9Ue7_hbUGGGYJbjo1K7Z5NNeOk\"\n",
    "BASE_URL = \"https://api.climateengine.org\"\n",
    "\n",
    "elevation = 'elevation/kenya_mean_elevation.csv'\n",
    "SHAPEFILE_PATH = 'counties/counties.shp'\n",
    "yield_dataset = f\"predictor/Yield Predicting Dataset {datetime.now().strftime('%Y-%m-%d')}.csv\"\n",
    "backup = f\"predictor/backup_means.csv\"\n",
    "    \n",
    "data_var = {\n",
    "    'ERA5': [\n",
    "        {'variable':[\"minimum_2m_air_temperature\",\"maximum_2m_air_temperature\",\"peth\",\"total_precipitation\"], 'statistic': \"mean\"}\n",
    "    ],\n",
    "    'SENTINEL2_TOA': [\n",
    "        {'variable':['NDVI'], 'statistic': \"mean\"},\n",
    "        {'variable':['NDVI'], 'statistic': \"max\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "def fetch_realtime_data(COUNTY_NAME):\n",
    "    # --- DATE RANGE ---\n",
    "    end_date = datetime.today()\n",
    "    start_date = end_date - timedelta(days=71)\n",
    "    START_DATE = start_date.strftime(\"%Y-%m-%d\")\n",
    "    END_DATE = end_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    \n",
    "    gdf = gpd.read_file(SHAPEFILE_PATH)\n",
    "    backup_data = pd.read_csv(backup)\n",
    "    \n",
    "    selected = gdf[gdf['county'].str.lower().replace(' ','').replace('-','') == COUNTY_NAME.lower().replace(' ','').replace('-','')]\n",
    "    backup_county = backup_data[backup_data['County'].str.lower().replace([' ','-'],'')==COUNTY_NAME.lower().replace(' ','').replace('-','')]\n",
    "    \n",
    "    if selected.empty:\n",
    "        print(f\"❌ County '{COUNTY_NAME}' not found in shapefile.\")\n",
    "    else:\n",
    "        row = selected.geometry.iloc[0]\n",
    "        simplified_row = row.simplify(tolerance=0.02, preserve_topology=True)\n",
    "        geometry_dict = mapping(simplified_row)\n",
    "        coordinates = geometry_dict['coordinates']\n",
    "        coords = json.dumps(coordinates)\n",
    "    \n",
    "        headers = {\"Authorization\": API_TOKEN}\n",
    "        print(f\"⏳ Downloading data for {COUNTY_NAME}...\")\n",
    "        url = f'{BASE_URL}/timeseries/native/coordinates'\n",
    "        predictors = pd.DataFrame()\n",
    "        \n",
    "                \n",
    "        for dataset, var_dict in data_var.items():\n",
    "            for item in var_dict:\n",
    "                statistic = item['statistic']\n",
    "                for var in item['variable']:    \n",
    "                    params = {\n",
    "                        \"coordinates\": coords,\n",
    "                        \"area_reducer\": statistic,\n",
    "                        \"dataset\": dataset,\n",
    "                        \"variable\": var,\n",
    "                        \"start_date\": START_DATE,\n",
    "                        \"end_date\": END_DATE,  \n",
    "                        }\n",
    "    \n",
    "                    if dataset !='SENTINEL2_TOA':\n",
    "                        var = var\n",
    "                    else:\n",
    "                        var = var + f\"_{statistic}\"\n",
    "                    print(f'Requesting {dataset} for {var}')\n",
    "                    response = requests.get(url, params=params, headers=headers)\n",
    "    \n",
    "                    if response.status_code == 200:\n",
    "                        res = response.json().get('Data',[])\n",
    "                        data = res[0]['Data']\n",
    "                        if data:             \n",
    "                           df = pd.DataFrame(data)\n",
    "                           df = df.rename(columns={col: f'{var}' for col in df.columns if col != 'Date'}) \n",
    "                           if predictors.empty:\n",
    "                               predictors = df             \n",
    "                           else:\n",
    "                               predictors = pd.merge(\n",
    "                               left= predictors,\n",
    "                               right= df,\n",
    "                               on= 'Date',\n",
    "                               how= 'outer'\n",
    "                               )\n",
    "                           print(f'✔ {var}')\n",
    "                        else:\n",
    "                            print(f\"⚠ No data found for {var}\")\n",
    "                            predictors[var] = backup_county[var].values[0]\n",
    "                    else:\n",
    "                        print(f\"❌ Error {response.status_code}: {response.text}...Using backup data for {var}\")\n",
    "                        predictors[var] = backup_county[var].values[0]\n",
    "                        \n",
    "    predict=predictors[predictors['NDVI_mean'] !=-9999]\n",
    "    predict.set_index('Date', inplace=True)\n",
    "    \n",
    "    predict_data = {}\n",
    "    \n",
    "    for col in predict.columns:\n",
    "        \n",
    "        if col != 'total_precipitation':\n",
    "            value = predict[col].mean()\n",
    "        elif col == 'total_precipitation':\n",
    "            value = (predict[col].sum()/predict[col].value_counts().sum())*365\n",
    "        predict_data[col] = value\n",
    "    \n",
    "        predict_df = pd.DataFrame([predict_data])\n",
    "    \n",
    "    predict_df['Temp_range'] = predict_df['maximum_2m_air_temperature']-predict_df['minimum_2m_air_temperature']\n",
    "    predict_df['County'] = COUNTY_NAME\n",
    "    \n",
    "    elev = pd.read_csv(elevation)\n",
    "    \n",
    "    full_predict_data  = pd.merge(\n",
    "        left= predict_df,\n",
    "        right= elev,\n",
    "        left_on= 'County',\n",
    "        right_on= 'county',\n",
    "        how= 'left'\n",
    "    )\n",
    "    \n",
    "    pH = 'pH/Kenya_counties_pH.csv'\n",
    "    ph = pd.read_csv(pH)\n",
    "    ph.drop(['system:index', '.geo'], axis=1, inplace=True)\n",
    "\n",
    "    full_predict_data  = pd.merge(\n",
    "        left= full_predict_data,\n",
    "        right= ph,\n",
    "        left_on= 'county',\n",
    "        right_on= 'county',\n",
    "        how= 'left'\n",
    "        )\n",
    "    \n",
    "    full_predict_data.drop(['county'],axis=1, inplace=True)\n",
    "    full_predict_data.head()\n",
    "    \n",
    "    full_predict_data.columns = ['mean Tmin','mean Tmax','Hargreaves PET','Precipitation','Mean NDVI','Max NDVI','Temp_range','County','meanElev','pH']\n",
    "    full_predict_data = full_predict_data[['County','meanElev','Max NDVI', 'Mean NDVI', 'mean Tmax', 'mean Tmin', 'Hargreaves PET', 'Precipitation','Temp_range','pH']]\n",
    "    \n",
    "    # try:\n",
    "    #     pd.read_csv(yield_dataset)\n",
    "    #     full_predict_data.to_csv(yield_dataset, mode='a', header=False, index=False)\n",
    "    # except FileNotFoundError:\n",
    "    #     full_predict_data.to_csv(yield_dataset, mode='w', header=True, index=False)\n",
    "\n",
    "    return full_predict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac9a42e5-d8f8-4389-8faa-3589817d0a81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T01:33:23.611836Z",
     "iopub.status.busy": "2025-10-24T01:33:23.611501Z",
     "iopub.status.idle": "2025-10-24T01:33:32.540614Z",
     "shell.execute_reply": "2025-10-24T01:33:32.539663Z",
     "shell.execute_reply.started": "2025-10-24T01:33:23.611814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Downloading data for Kisii...\n",
      "Requesting ERA5 for minimum_2m_air_temperature\n",
      "✔ minimum_2m_air_temperature\n",
      "Requesting ERA5 for maximum_2m_air_temperature\n",
      "✔ maximum_2m_air_temperature\n",
      "Requesting ERA5 for peth\n",
      "✔ peth\n",
      "Requesting ERA5 for total_precipitation\n",
      "✔ total_precipitation\n",
      "Requesting SENTINEL2_TOA for NDVI_mean\n",
      "✔ NDVI_mean\n",
      "Requesting SENTINEL2_TOA for NDVI_max\n",
      "✔ NDVI_max\n"
     ]
    }
   ],
   "source": [
    "a = fetch_realtime_data('Kisii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c37c1d2-0e25-4380-b1e3-1aa03d140ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-24T01:40:32.605525Z",
     "iopub.status.busy": "2025-10-24T01:40:32.605066Z",
     "iopub.status.idle": "2025-10-24T01:40:32.610818Z",
     "shell.execute_reply": "2025-10-24T01:40:32.609977Z",
     "shell.execute_reply.started": "2025-10-24T01:40:32.605502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.fetch_realtime_data(COUNTY_NAME)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_realtime_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e14689-7d47-4bdd-9c42-604d981f791d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
